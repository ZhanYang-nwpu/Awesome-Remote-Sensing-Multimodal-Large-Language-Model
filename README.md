# Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language)


ğŸ“¢ A collection of remote sensing multimodal large language model papers focusing on the vision-language domain.

##### Author: Yang Zhan
**School of Artificial Intelligence, OPtics, and ElectroNics (iOPEN), Northwestern Polytechnical University**
## Please share a <font color='orange'>STAR â­</font> if this project does help


## ğŸ“¢ Latest Updates
In this repository, we will collect and document researchers and their outstanding work related to remote sensing multimodal large language model (vision-language).
- **The list will be continuously updated** ğŸ”¥ğŸ”¥
- ğŸ“¦ coming soon! ğŸš€
---



## Content
- [Papers](#papers)
- [Remote Sensing Vision-Language Dataset](#Remote-Sensing-Vision-Language-Dataset)
- [related: Remote Sensing Vision-Language Foundation Models](#related)


## Papers
- ğŸ”¥ **Jan-18-24: SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model**

arXiv 2024 (arXiv:2401.09712). *Y. Zhan, Z. Xiong, and Y. Yuan.* [[Paper](https://arxiv.org/abs/2401.09712)][[Code](https://github.com/ZhanYang-nwpu/SkyEyeGPT)]

- ğŸ”¥ **Nov-30-23: Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs**

arXiv 2023 (arXiv:2311.14656). *J. Roberts, T. LÃ¼ddecke, R. Sheikh, K. Han, and S. Albanie.* [[Paper](https://arxiv.org/abs/2311.14656)][[Code](https://github.com/jonathan-roberts1/charting-new-territories)]

- ğŸ”¥ **Nov-28-23: GeoChat: Grounded Large Vision-Language Model for Remote Sensing**

arXiv 2023 (arXiv:2311.15826). *K. Kuckreja, M. S. Danish, M. Naseer, A. Das, S. Khan, and F. S. Khan.* [[Paper](http://arxiv.org/abs/2311.15826)][[Code](https://github.com/mbzuai-oryx/geochat)]

- ğŸ”¥ **Jul-28-23: RSGPT: A Remote Sensing Vision Language Model and Benchmark** 

arXiv 2023 (arXiv:2307.15266). *Y. Hu, J. Yuan, and C. Wen.* [[Paper](https://arxiv.org/abs/2307.15266)][[Code](https://github.com/Lavender105/RSGPT)]

## Remote Sensing Vision-Language Dataset
- ğŸ”¥ **Dec-20-23: SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing**

AAAI 2024 (arXiv:2312.12856). *Z. Wang, R. Prabha, T. Huang, J. Wu, and R. Rajagopal.* [[Paper](http://arxiv.org/abs/2312.12856)][[Code](https://github.com/wangzhecheng/SkyScript)]


## related: Remote Sensing Vision-Language Foundation Models
- ğŸ”¥ **Dec-12-23: Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment**

arXiv 2023 (arXiv:2312.06960). *U. Mall, C. P. Phoo, M. K. Liu, C. Vondrick, B. Hariharan, and K. Bala.* [[Paper](http://arxiv.org/abs/2312.06960)][[Code]:Null]

- ğŸ”¥ **Aug-10-23: RemoteCLIP: A Vision Language Foundation Model for Remote Sensing**

arXiv 2023 (arXiv:2306.11029). *F. Liu, D. Chen, Z. Guan, X. Zhou, J. Zhu, and J. Zhou.* [[Paper](https://arxiv.org/abs/2306.11029)][[Code](https://github.com/ChenDelong1999/RemoteCLIP)]



