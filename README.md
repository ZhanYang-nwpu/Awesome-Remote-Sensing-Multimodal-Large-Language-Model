
# Awesome-Remote-Sensing-Multimodal-Large-Language-Models


üî•üî•üî• **Multimodal Large Language Models for Remote Sensing: A Survey**  
**[Project Page][This Page](https://github.com/ZhanYang-nwpu/RS-MLLMs)** | 

**School of Artificial Intelligence, OPtics, and ElectroNics (iOPEN), Northwestern Polytechnical University**

<div align='center'> :sparkles: The <b>first survey</b> for Multimodal Large Language Models for Remote Sensing (RS-MLLMs). </div>  


‚ú®‚ú®‚ú® Behold our meticulously curated trove of RS-MLLMs resources!!!

üéâüöÄüí° The website will be updated in real-time to track the latest state of RS-MLLMs!!!

üìëüìöüîç Feast your eyes on an assortment of model architecture, training pipelines, datasets, comprehensive evaluation benchmarks, intelligent agents for remote sensing, techniques for instruction tuning, and much more. 

üåüüî•üì¢ A collection of remote sensing multimodal large language model papers focusing on the vision-language domain.


<p align="center">
    <img src="./images/1-timeline.jpg" width="100%" height="100%">
</p>

<font size=7><div align='center' > :apple: Multimodal Large Language Models for Remote Sensing </div></font>  

<p align="center">
    <img src="./images/6-timeline-agent.jpg" width="70%" height="100%">
</p>
<font size=7><div align='center' > :apple: Intelligent Agents for Remote Sensing </div></font>  



## Please share a <font color='orange'>STAR ‚≠ê</font> if this project does help




## üì¢ Latest Updates
In this repository, we will collect and document researchers and their outstanding work related to remote sensing multimodal large language model (vision-language).
- **The list will be continuously updated** üî•üî•
- üì¶ coming soon! üöÄ
- **May-22-2024**: The **first RS-MLLMs review** manuscript has been submitted for review. üî•üî•
  


---
<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome Papers](#awesome-papers)
  - [Multimodal Large Language Models for Remote Sensing](#multimodal-large-language-models-for-remote-sensing)
  - [Intelligent Agents for Remote Sensing](#intelligent-agents-for-remote-sensing)
  - [Vision-Language Pre-training Models for Remote Sensing](#vision-language-pre-training-models-for-remote-sensing)
  - [Survey Papers for Remote Sensing Vision-Language Tasks](#survey-papers-for-remote-sensing-vision-language-tasks)
  - [Others](#others)
- [Awesome Datasets](#awesome-datasets)
  - [Datasets of Pre-Training for Alignment](#datasets-of-pre-training-for-alignment)
  - [Datasets of Multimodal Instruction Tuning](#datasets-of-multimodal-instruction-tuning)
- [Latest Evaluation Benchmarks for Remote Sensing Vision-Language Tasks](#latest-evaluation-benchmarks-for-remote-sensing-vision-language-tasks)
  - [Remote Sensing Image Captioning and Aerial Video Captioning](#remote-sensing-image-captioning-and-aerial-video-captioning)
  - [Remote Sensing Visual Question Answering and Remote Sensing Visual Grounding](#remote-sensing-visual-question-answering-and-remote-sensing-visual-grounding)
  - [Remote Sensing Image-Text Retrieval](#remote-sensing-image-text-retrieval)
  - [Remote Sensing Scene Classification](#remote-sensing-scene-classification)
---

# Awesome Papers

## Multimodal Large Language Models for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [**RingMoGPT: A Unified Remote Sensing Foundation Model for Vision, Language, and grounded tasks**](https://ieeexplore.ieee.org/abstract/document/10777289/authors#authors) <br>P. Wang, H. Hu, B. Tong, Z. Zhang, F. Yao, Y. Feng, Z. Zhu, H. Chang, W. Diao, Q. Ye, and X. Sun C<br>| T-GRS | 2024-12-04 | - | - |
|  [**RS-MoE: Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering**](https://arxiv.org/abs/2411.01595) <br>Lin, H., Hong, D., Ge, S., Luo, C., Jiang, K., Jin, H., and Wen, C<br>| arXiv | 2024-11-03 | - | - |
| ![Star](https://img.shields.io/github/stars/HosamGen/GeoLLaVA.svg?style=social&label=Star) <br> [**GeoLLaVA: Efficient Fine-Tuned Vision-Language Models for Temporal Change Detection in Remote Sensing**](https://arxiv.org/pdf/2410.19552) <br>Elgendy, H., Sharshar, A., Aboeitta, A., Ashraf, Y., and Guizani, M. <br>| arXiv | 2024-10-25 | [Github](https://github.com/HosamGen/GeoLLaVA) | - |
| ![Star](https://img.shields.io/github/stars/ermongroup/TEOChat.svg?style=social&label=Star) <br> [**TEOChat: Large Language and Vision Assistant for Temporal Earth Observation Data**](https://arxiv.org/pdf/2410.06234) <br>J. Irvin, Jeremy Andrew, et al. <br>| arXiv | 2024-10-08 | [Github](https://github.com/ermongroup/TEOChat) | - |
| ![Star](https://img.shields.io/github/stars/wivizhang/EarthMarker.svg?style=social&label=Star) <br> [**EarthMarker: A Visual Prompting MLLM for Region-level and Point-level Remote Sensing Imagery Comprehension**](https://arxiv.org/pdf/2407.13596) <br>Zhang, W., Cai, M., Zhang, T., Zhuang, Y., and Mao, X. <br>| arXiv | 2024-07-18 | [Github](https://github.com/wivizhang/EarthMarker) | - |
| ![Star](https://img.shields.io/github/stars/Luo-Z13/SkySenseGPT.svg?style=social&label=Star) <br> [**SkySenseGPT: A Fine-Grained Instruction Tuning Dataset and Model for Remote Sensing Vision-Language Understanding**](http://arxiv.org/abs/2406.10100) <br>J. Luo et al. <br>| arXiv | 2024-06-14 | [Github](https://github.com/Luo-Z13/SkySenseGPT) | - |
| ![Star](https://img.shields.io/github/stars/BigData-KSU/RS-LLaVA.svg?style=social&label=Star) <br> [**RS-LLaVA: A Large Vision-Language Model for Joint Captioning and Question Answering in Remote Sensing Imagery**](https://www.mdpi.com/2072-4292/16/9/1477) <br>Y. Bazi, L. Bashmal, M. M. Al Rahhal, R. Ricci, and F. Melgani. <br>| Remote Sensing | 2024-04-23 | [Github](https://github.com/BigData-KSU/RS-LLaVA) | - |
| ![Star](https://img.shields.io/github/stars/opendatalab/H2RSVLM.svg?style=social&label=Star) <br> [**H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model**](https://arxiv.org/abs/2403.20213.pdf) <br> C. Pang, W. Jiang, L. Jiayu, L. Yi, S. Jiaxing, L. Weijia, W. Xingxing, W. Shuai, F. Litong, X. Guisong, H.Conghui. <br>| arXiv | 2024-03-29 | [Github](https://github.com/opendatalab/H2RSVLM) | - |
| [**Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery**](https://arxiv.org/abs/2403.03790.pdf) <br>W. Zhang, M. Cai, T. Zhang, G. Lei, Y. Zhuang, and X. Mao.<br>| arXiv | 2024-03-06 | - | - |
| [**Large Language Models for Captioning and Retrieving Remote Sensing Images**](https://arxiv.org/abs/2402.06475.pdf) <br>J. D. Silva, J. Magalhaes, and D. Tuia.<br>| arXiv | 2024-02-09 | - | - |
| ![Star](https://img.shields.io/github/stars/NJU-LHRS/LHRS-Bot.svg?style=social&label=Star) <br> [**LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model**](https://arxiv.org/abs/2402.02544v2.pdf) <br>D. Muhtar, Z. Li, F. Gu, X. Zhang, and P. Xiao. <br>| arXiv | 2024-02-04 | [Github](https://github.com/NJU-LHRS/LHRS-Bot) | - |
| ![Star](https://img.shields.io/github/stars/wivizhang/EarthGPT.svg?style=social&label=Star) <br> [**EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain**](https://arxiv.org/abs/2401.16822.pdf) <br>W. Zhang, M. Cai, T. Zhang, Y. Zhuang, and X. Mao. <br>| arXiv | 2024-01-30 | [Github](https://github.com/wivizhang/EarthGPT) | accepted by IEEE-TGRS|
| ![Star](https://img.shields.io/github/stars/ZhanYang-nwpu/SkyEyeGPT.svg?style=social&label=Star) <br> [**SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model**](https://arxiv.org/abs/2401.09712.pdf) <br>Y. Zhan, Z. Xiong, and Y. Yuan. <br>| arXiv | 2024-01-18 | [Github](https://github.com/ZhanYang-nwpu/SkyEyeGPT) | [Dataset](https://huggingface.co/datasets/ZhanYang-nwpu/SkyEye-968k) |
| ![Star](https://img.shields.io/github/stars/mbzuai-oryx/geochat.svg?style=social&label=Star) <br> [**GeoChat: Grounded Large Vision-Language Model for Remote Sensing**](http://arxiv.org/abs/2311.15826.pdf) <br>K. Kuckreja, M. S. Danish, M. Naseer, A. Das, S. Khan, and F. S. Khan. <br>| arXiv | 2023-11-24 | [Github](https://github.com/mbzuai-oryx/geochat) | accepted by CVPR-24 |
| ![Star](https://img.shields.io/github/stars/Lavender105/RSGPT.svg?style=social&label=Star) <br> [**RSGPT: A Remote Sensing Vision Language Model and Benchmark**](https://arxiv.org/abs/2307.15266.pdf) <br>Y. Hu, J. Yuan, and C. Wen. <br>| arXiv | 2023-07-28 | [Github](https://github.com/Lavender105/RSGPT) | - |


## Intelligent Agents for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [**RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents**](https://arxiv.org/abs/2406.07089) <br>W. Xu, Z. Yu, Y. Wang, J. Wang, and M. Peng.<br>| arXiv | 2024-06-11 | - | - |
| [**GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots**](https://arxiv.org/abs/2404.15500.pdf) <br>S. Singh, M. Fore, D. Stamoulis, and D. Group.<br>| arXiv | 2024-04-23 | - | - |
| [**Evaluating Tool-Augmented Agents in Remote Sensing Platforms**](https://arxiv.org/abs/2405.00709v1.pdf) <br>S. Singh, M. Fore, and D. Stamoulis.<br>| arXiv | 2024-04-23 | - | - |
| ![Star](https://img.shields.io/github/stars/Chen-Yang-Liu/Change-Agent.svg?style=social&label=Star) <br> [**Change-Agent: Towards Interactive Comprehensive Remote Sensing Change Interpretation and Analysis**](https://arxiv.org/abs/2403.19646.pdf) <br>C. Liu, K. Chen, H. Zhang, Z. Qi, Z. Zou, and Z. Shi.<br>| arXiv | 2024-04-01 | [Github](https://github.com/Chen-Yang-Liu/Change-Agent) | - |
| ![Star](https://img.shields.io/github/stars/HaonanGuo/Remote-Sensing-ChatGPT.svg?style=social&label=Star) <br> [**Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and Visual Models**](https://arxiv.org/abs/2401.09083v1.pdf) <br>H. Guo, X. Su, C. Wu, B. Du, L. Zhang, and D. Li.<br>| arXiv | 2024-01-17 | [Github](https://github.com/HaonanGuo/Remote-Sensing-ChatGPT) | - |
| [**Tree-GPT: Modular Large Language Model Expert System for Forest Remote Sensing Image Understanding and Interactive Analysis**](http://arxiv.org/abs/2310.04698.pdf) <br>S. Du, S. Tang, W. Wang, X. Li, and R. Guo.<br>| arXiv | 2023-10-07 | - | - |




## Vision-Language Pre-training Models for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/om-ai-lab/RS5M.svg?style=social&label=Star) <br> [**RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Large Vision-Language Model for Remote Sensing**](https://arxiv.org/abs/2306.11300.pdf) <br>Z. Zhang, T. Zhao, Y. Guo, and J. Yin.<br>| arXiv | 2024-01-02 | [Github](https://github.com/om-ai-lab/RS5M) | accepted by IEEE-TGRS |
| ![Star](https://img.shields.io/github/stars/ChenDelong1999/RemoteCLIP.svg?style=social&label=Star) <br> [**RemoteCLIP: A Vision Language Foundation Model for Remote Sensing**](https://ieeexplore.ieee.org/abstract/document/10504785) <br>F. Liu, D. Chen, Z. Guan, X. Zhou, J. Zhu, and J. Zhou.<br>| T-GRS | 2024-04-18 | [Github](https://github.com/ChenDelong1999/RemoteCLIP) | [arXiv](https://arxiv.org/abs/2306.11029.pdf) |
| [**Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment**](https://openreview.net/pdf?id=w9tc699w3Z) <br>U. Mall, C. P. Phoo, M. K. Liu, C. Vondrick, B. Hariharan, and K. Bala.<br>| ICLR | 2024-01-16 | [Project](https://graft.cs.cornell.edu/) | [arXiv](http://arxiv.org/abs/2312.06960.pdf) |
 ![Star](https://img.shields.io/github/stars/lx709/RS-CLIP.svg?style=social&label=Star) <br> [**RS-CLIP: Zero Shot Remote Sensing Scene Classification via Contrastive Vision-Language Supervision**](https://www.sciencedirect.com/science/article/pii/S1569843223003217) <br>X. Li, C. Wen, Y. Hu, and N. Zhou.<br>| JAG | 2023-09-18 | [Github](https://github.com/lx709/RS-CLIP) | - |
 ![Star](https://img.shields.io/github/stars/ZhanYang-nwpu/PE-RSITR.svg?style=social&label=Star) <br> [**Parameter-Efficient Transfer Learning for Remote Sensing Image‚ÄìText Retrieval**](https://ieeexplore.ieee.org/abstract/document/10231134) <br>Y. Yuan, Y. Zhan, and Z. Xiong.<br>| T-GRS | 2023-08-28 | [Github](https://github.com/ZhanYang-nwpu/PE-RSITR) | [arXiv](https://arxiv.org/abs/2308.12509.pdf) |



## Survey Papers for Remote Sensing Vision-Language Tasks
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/zytx121/Awesome-VLGFM.svg?style=social&label=Star) <br>[**Towards Vision-Language Geo-Foundation Model: A Survey**](http://arxiv.org/abs/2406.09385) <br>Y. Zhou, L. Feng, Y. Ke, X. Jiang, J. Yan, and W. Zhang.<br>| arXiv | 2024-06-13 | [Github](https://github.com/zytx121/Awesome-VLGFM) | [arXiv](http://arxiv.org/abs/2406.09385) |
| [**Vision-Language Models in Remote Sensing: Current progress and future trends**](https://ieeexplore.ieee.org/document/10506064) <br>X. Li, C. Wen, Y. Hu, Z. Yuan, and X. X. Zhu.<br>| MGRS | 2024-04-22 | - | - |
| [**Language Integration in Remote Sensing: Tasks, datasets, and future directions**](https://ieeexplore.ieee.org/abstract/document/10278197) <br>L. Bashmal, Y. Bazi, F. Melgani, M. M. Al Rahhal, and M. A. Al Zuair.<br>| MGRS | 2023-10-11 | - | - |
| [**Brain-Inspired Remote Sensing Foundation Models and Open Problems: A Comprehensive Survey**](https://ieeexplore.ieee.org/abstract/document/10278197) <br>L. Jiao et al.<br>| JSTARS | 2023-09-18 | - | - |



## Others
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [**On the Foundations of Earth and Climate Foundation Models**](https://arxiv.org/pdf/2405.04285.pdf) <br>X. X. Zhu et al.<br>| arXiv | 2024-05-07 | [Github](https://github.com/zhu-xlab/EarthFoundationModels) | - |
| [**On the Promises and Challenges of Multimodal Foundation Models for Geographical, Environmental, Agricultural, and Urban Planning Applications**](https://arxiv.org/abs/2312.17016.pdf) <br>C. Tan et al.<br>| arXiv | 2023-12-23 | - | - |
| ![Star](https://img.shields.io/github/stars/jonathan-roberts1/charting-new-territories.svg?style=social&label=Star) <br> [**Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs**](https://arxiv.org/abs/2311.14656.pdf) <br>J. Roberts, T. L√ºddecke, R. Sheikh, K. Han, and S. Albanie. <br>| arXiv | 2023-11-24 | [Github](https://github.com/jonathan-roberts1/charting-new-territories) | - |
| [**The Potential of Visual ChatGPT for Remote Sensing**](https://www.mdpi.com/2072-4292/15/13/3232) <br>L. P. Osco, E. L. de Lemos, W. N. Gon√ßalves, A. P. M. Ramos, and J. Marcato Junior.<br>| Remote Sensing | 2023-06-22 | - | - |




# Awesome Datasets

## Datasets of Pre-Training for Alignment
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/SlytherinGe/RSTeller.svg?style=social&label=Star) <be> [**RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models**](https://arxiv.org/pdf/2408.14744.pdf) <br>J. Ge, Y. Zheng, K. Guo, and J. Liang.<br>| arXiv | 2024-08-27 | [Github](https://github.com/SlytherinGe/RSTeller) | [Link](https://huggingface.co/datasets/SlytherinGe/RSTeller) |
| ![Star](https://img.shields.io/github/stars/zhu-xlab/ChatEarthNet.svg?style=social&label=Star) <be> [**ChatEarthNet: A Global-Scale, High-Quality Image-Text Dataset for Remote Sensing**](https://arxiv.org/abs/2402.11325.pdf) <br>Z. Yuan, Z. Xiong, L. Mou, and X. X. Zhu.<br>| arXiv | 2024-02-17 | [Github](https://github.com/zhu-xlab/ChatEarthNet) | [Link](https://zenodo.org/records/11003436) |
| ![Star](https://img.shields.io/github/stars/om-ai-lab/RS5M.svg?style=social&label=Star) <br> [**RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Large Vision-Language Model for Remote Sensing**](https://arxiv.org/abs/2306.11300.pdf) <br>Z. Zhang, T. Zhao, Y. Guo, and J. Yin.<br>| arXiv | 2024-01-02 | [Github](https://github.com/om-ai-lab/RS5M) | - |
| ![Star](https://img.shields.io/github/stars/wangzhecheng/SkyScript.svg?style=social&label=Star) <br> [**SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing**](https://doi.org/10.1609/aaai.v38i6.28393) <br>Z. Wang, R. Prabha, T. Huang, J. Wu, and R. Rajagopal.<br>| AAAI | 2024-03-24 | [Github](https://github.com/wangzhecheng/SkyScript) | [arXiv](http://arxiv.org/abs/2312.12856.pdf) |


<p align="center">
    <img src="./images/itpair.jpg" width="80%" height="100%">
</p>


## Datasets of Multimodal Instruction Tuning
| Name | Paper | Link | Note |
|:-----|:-----:|:----:|:-----:|
| **DDFAV** | [DDFAV: Remote Sensing Large Vision Language Models Dataset and Evaluation Benchmark](https://arxiv.org/pdf/2411.02733) | [Link](https://github.com/HaodongLi2024/rspope) | 27.7k | 
| **VRSBench** | [VRSBench: A Versatile Vision-Language Benchmark Dataset for Remote Sensing Image Understanding](https://arxiv.org/pdf/2406.12384) | [Link](https://vrsbench.github.io/) | 29.6k | 
| **FIT-RS** | [SkySenseGPT: A Fine-Grained Instruction Tuning Dataset and Model for Remote Sensing Vision-Language Understanding](http://arxiv.org/abs/2406.10100) | [Link](https://huggingface.co/datasets/ll-13/FIT-RS) | 1800.8k | 
| **RS-GPT4V** | [RS-GPT4V: A Unified Multimodal Instruction-Following Dataset for Remote Sensing Image Understanding](https://arxiv.org/abs/2406.09385) | [Link](https://github.com/GeoX-Lab/RS-GPT4V) | 991k | 
| **RS-instructions** | [RS-LLaVA: A Large Vision-Language Model for Joint Captioning and Question Answering in Remote Sensing Imagery](https://www.mdpi.com/2072-4292/16/9/1477) | [Link](https://github.com/BigData-KSU/RS-LLaVA) | 7,058 | 
| **SkyEye-968k** | [SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model](https://arxiv.org/abs/2401.09712.pdf) | [Link](https://huggingface.co/datasets/ZhanYang-nwpu/SkyEye-968k) | 968k | 
| **Multi-task Instruction** | [LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model](https://arxiv.org/abs/2402.02544v2.pdf) | [Link](https://github.com/NJU-LHRS/LHRS-Bot) | 42,322 |
| **MMRS-1M** | [EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain](https://arxiv.org/abs/2401.16822.pdf) | [Link](https://github.com/wivizhang/EarthGPT) | >1M |
| **RS-ClsQaGrd-Instruct** | [H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model](https://arxiv.org/abs/2403.20213.pdf) | [Link](https://github.com/opendatalab/H2RSVLM) | 78k |
| **MMShip** | [Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery](https://arxiv.org/abs/2403.03790.pdf) | [Link]() | 81k |
| **RS-Specialized-Instruct** |[H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model](https://arxiv.org/abs/2403.20213.pdf) | [Link](https://github.com/opendatalab/H2RSVLM) | 29.8k |
| **RS multimodal instruction** | [GeoChat: Grounded Large Vision-Language Model for Remote Sensing](http://arxiv.org/abs/2311.15826.pdf) | [Link](https://github.com/mbzuai-oryx/geochat) | 318k |
| **LHRS-Instruct** | [LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model](https://arxiv.org/abs/2402.02544v2.pdf) | [Link](https://github.com/NJU-LHRS/LHRS-Bot) | 39.8k |
| **HqDC-Instruct** | [H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model](https://arxiv.org/abs/2403.20213.pdf) | [Link](https://github.com/opendatalab/H2RSVLM) | 30k |



<p align="center">
    <img src="./images/instruct.jpg" width="80%" height="100%">
</p>




# Latest Evaluation Benchmarks for Remote Sensing Vision-Language Tasks

## Remote Sensing Image Captioning and Aerial Video Captioning
<p align="center">
    <img src="./images/caption.jpg" width="80%" height="100%">
</p>


## Remote Sensing Visual Question Answering and Remote Sensing Visual Grounding
<p align="center">
    <img src="./images/vqavg.jpg" width="80%" height="100%">
</p>



## Remote Sensing Image-Text Retrieval
<p align="center">
    <img src="./images/itretrieval.jpg" width="80%" height="100%">
</p>

## Remote Sensing Scene Classification
<p align="center">
    <img src="./images/rssc.jpg" width="80%" height="100%">
</p>



## ü§ñ Contact
If you have any questions about this project, please feel free to contact zhanyangnwpu@gmail.com.



